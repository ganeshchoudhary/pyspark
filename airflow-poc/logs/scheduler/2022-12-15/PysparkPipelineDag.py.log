[2022-12-15T12:17:14.005+0000] {processor.py:153} INFO - Started process (PID=10962) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:17:14.006+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:17:14.011+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:17:14.011+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:17:14.042+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:17:14.181+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:17:14.181+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:pyspark-pipeline
[2022-12-15T12:17:14.187+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:17:14.187+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:pyspark-pipeline
[2022-12-15T12:17:14.194+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:17:14.193+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:pyspark-pipeline
[2022-12-15T12:17:14.194+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:17:14.194+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:17:14.203+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:17:14.203+0000] {dag.py:2697} INFO - Creating ORM DAG for pyspark-pipeline
[2022-12-15T12:17:14.213+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:17:14.213+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:17:14.228+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.228 seconds
[2022-12-15T12:17:44.663+0000] {processor.py:153} INFO - Started process (PID=11034) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:17:44.663+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:17:44.664+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:17:44.664+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:17:44.675+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:17:44.736+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:17:44.736+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:17:44.757+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:17:44.757+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:17:44.771+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.111 seconds
[2022-12-15T12:18:14.953+0000] {processor.py:153} INFO - Started process (PID=11121) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:18:14.965+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:18:14.965+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:18:14.965+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:18:14.975+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:18:15.004+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:18:15.004+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:18:15.027+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:18:15.026+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:18:15.043+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.092 seconds
[2022-12-15T12:18:45.385+0000] {processor.py:153} INFO - Started process (PID=11192) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:18:45.396+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:18:45.398+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:18:45.397+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:18:45.412+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:18:45.437+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:18:45.436+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:18:45.454+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:18:45.454+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:18:45.467+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.086 seconds
[2022-12-15T12:19:04.002+0000] {processor.py:153} INFO - Started process (PID=11250) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:19:04.003+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:19:04.003+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:19:04.003+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:19:04.013+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:19:04.044+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:19:04.044+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:19:04.068+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:19:04.068+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:19:04.085+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.086 seconds
[2022-12-15T12:19:34.396+0000] {processor.py:153} INFO - Started process (PID=11322) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:19:34.396+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:19:34.397+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:19:34.397+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:19:34.407+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:19:34.433+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:19:34.433+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:19:34.451+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:19:34.451+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:19:34.463+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.069 seconds
[2022-12-15T12:20:04.617+0000] {processor.py:153} INFO - Started process (PID=11405) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:20:04.618+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:20:04.618+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:20:04.618+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:20:04.628+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:20:04.657+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:20:04.657+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:20:04.675+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:20:04.675+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:20:04.689+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.074 seconds
[2022-12-15T12:20:34.910+0000] {processor.py:153} INFO - Started process (PID=11477) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:20:34.910+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:20:34.911+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:20:34.911+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:20:34.920+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:20:34.949+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:20:34.949+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:20:34.971+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:20:34.971+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:20:34.983+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.075 seconds
[2022-12-15T12:21:05.271+0000] {processor.py:153} INFO - Started process (PID=11564) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:21:05.272+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:21:05.272+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:21:05.272+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:21:05.282+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:21:05.309+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:21:05.309+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:21:05.327+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:21:05.326+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:21:05.342+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.073 seconds
[2022-12-15T12:21:35.502+0000] {processor.py:153} INFO - Started process (PID=11636) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:21:35.503+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:21:35.504+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:21:35.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:21:35.513+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:21:35.541+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:21:35.541+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:21:35.559+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:21:35.559+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:21:35.574+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.074 seconds
[2022-12-15T12:22:06.012+0000] {processor.py:153} INFO - Started process (PID=11723) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:22:06.012+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:22:06.013+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:22:06.013+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:22:06.022+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:22:06.049+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:22:06.049+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:22:06.066+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:22:06.066+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:22:06.079+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.069 seconds
[2022-12-15T12:22:36.498+0000] {processor.py:153} INFO - Started process (PID=11795) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:22:36.510+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:22:36.510+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:22:36.510+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:22:36.521+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:22:36.558+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:22:36.558+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:22:36.581+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:22:36.580+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:22:36.595+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.099 seconds
[2022-12-15T12:23:07.010+0000] {processor.py:153} INFO - Started process (PID=11883) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:23:07.011+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:23:07.012+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:23:07.011+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:23:07.020+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:23:07.051+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:23:07.051+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:23:07.069+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:23:07.069+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:23:07.084+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.075 seconds
[2022-12-15T12:23:37.527+0000] {processor.py:153} INFO - Started process (PID=11955) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:23:37.528+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:23:37.528+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:23:37.528+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:23:37.542+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:23:37.573+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:23:37.573+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:23:37.595+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:23:37.595+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:23:37.615+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.091 seconds
[2022-12-15T12:24:08.384+0000] {processor.py:153} INFO - Started process (PID=12043) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:24:08.385+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:24:08.385+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:24:08.385+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:24:08.395+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:24:08.420+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:24:08.420+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:24:08.438+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:24:08.438+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:24:08.455+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.073 seconds
[2022-12-15T12:24:38.836+0000] {processor.py:153} INFO - Started process (PID=12132) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:24:38.836+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:24:38.837+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:24:38.837+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:24:38.846+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:24:38.875+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:24:38.875+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:24:38.895+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:24:38.894+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:24:38.911+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.079 seconds
[2022-12-15T12:25:09.450+0000] {processor.py:153} INFO - Started process (PID=12204) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:25:09.450+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:25:09.451+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:25:09.451+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:25:09.460+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:25:09.491+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:25:09.491+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:25:09.512+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:25:09.512+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:25:09.525+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.077 seconds
[2022-12-15T12:25:29.545+0000] {processor.py:153} INFO - Started process (PID=12257) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:25:29.546+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:25:29.546+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:25:29.546+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:25:29.556+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:25:29.606+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:25:29.606+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:25:29.621+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:25:29.621+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:25:29.636+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.093 seconds
[2022-12-15T12:25:59.963+0000] {processor.py:153} INFO - Started process (PID=12330) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:25:59.975+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:25:59.976+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:25:59.976+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:25:59.994+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:26:00.019+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:26:00.019+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:26:00.036+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:26:00.036+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:26:00.049+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.091 seconds
[2022-12-15T12:26:30.375+0000] {processor.py:153} INFO - Started process (PID=12418) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:26:30.386+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:26:30.387+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:26:30.387+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:26:30.396+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:26:30.433+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:26:30.433+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:26:30.452+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:26:30.452+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:26:30.465+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.093 seconds
[2022-12-15T12:26:51.800+0000] {processor.py:153} INFO - Started process (PID=12490) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:26:51.811+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:26:51.811+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:26:51.811+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:26:51.834+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:26:51.916+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:26:51.916+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:26:51.939+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:26:51.939+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:26:51.955+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.158 seconds
[2022-12-15T12:27:22.090+0000] {processor.py:153} INFO - Started process (PID=12561) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:27:22.090+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:27:22.091+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:27:22.091+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:27:22.100+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:27:22.126+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:27:22.125+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:27:22.143+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:27:22.143+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:27:22.156+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.068 seconds
[2022-12-15T12:27:27.120+0000] {processor.py:153} INFO - Started process (PID=12578) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:27:27.121+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:27:27.121+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:27:27.121+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:27:27.131+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:27:27.183+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:27:27.182+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:27:27.201+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:27:27.200+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:27:27.235+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.116 seconds
[2022-12-15T12:27:57.688+0000] {processor.py:153} INFO - Started process (PID=12650) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:27:57.688+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:27:57.688+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:27:57.688+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:27:57.699+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:27:57.728+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:27:57.728+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:27:57.747+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:27:57.747+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:27:57.763+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.079 seconds
[2022-12-15T12:28:27.811+0000] {processor.py:153} INFO - Started process (PID=12738) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:28:27.812+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:28:27.813+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:28:27.812+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:28:27.821+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:28:27.845+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:28:27.845+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:28:27.863+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:28:27.863+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:28:27.876+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.067 seconds
[2022-12-15T12:28:58.258+0000] {processor.py:153} INFO - Started process (PID=12810) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:28:58.270+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:28:58.271+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:28:58.271+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:28:58.286+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:28:58.310+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:28:58.310+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:28:58.328+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:28:58.328+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:28:58.339+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.084 seconds
[2022-12-15T12:29:28.620+0000] {processor.py:153} INFO - Started process (PID=12898) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:29:28.632+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:29:28.632+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:29:28.632+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:29:28.648+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:29:28.672+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:29:28.672+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:29:28.688+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:29:28.688+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:29:28.702+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.084 seconds
[2022-12-15T12:29:59.327+0000] {processor.py:153} INFO - Started process (PID=12971) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:29:59.338+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:29:59.339+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:29:59.339+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:29:59.356+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:29:59.381+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:29:59.381+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:29:59.397+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:29:59.397+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:29:59.409+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.085 seconds
[2022-12-15T12:30:29.890+0000] {processor.py:153} INFO - Started process (PID=13060) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:30:29.902+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:30:29.903+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:30:29.902+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:30:29.914+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:30:29.938+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:30:29.938+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:30:29.955+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:30:29.955+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:30:29.968+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.081 seconds
[2022-12-15T12:31:00.423+0000] {processor.py:153} INFO - Started process (PID=13132) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:31:00.423+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:31:00.424+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:31:00.424+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:31:00.436+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:31:00.467+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:31:00.467+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:31:00.487+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:31:00.487+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:31:00.501+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.080 seconds
[2022-12-15T12:31:31.156+0000] {processor.py:153} INFO - Started process (PID=13221) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:31:31.157+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:31:31.158+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:31:31.158+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:31:31.169+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:31:31.194+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:31:31.193+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:31:31.211+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:31:31.211+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:31:31.225+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.073 seconds
[2022-12-15T12:32:01.452+0000] {processor.py:153} INFO - Started process (PID=13293) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:32:01.453+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:32:01.453+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:32:01.453+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:32:01.464+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:32:01.487+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:32:01.487+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:32:01.504+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:32:01.504+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:32:01.517+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.068 seconds
[2022-12-15T12:32:32.292+0000] {processor.py:153} INFO - Started process (PID=13381) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:32:32.303+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:32:32.305+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:32:32.304+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:32:32.322+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:32:32.345+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:32:32.345+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:32:32.362+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:32:32.362+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:32:32.372+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.084 seconds
[2022-12-15T12:33:02.720+0000] {processor.py:153} INFO - Started process (PID=13452) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:33:02.731+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:33:02.732+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:33:02.732+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:33:02.747+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:33:02.774+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:33:02.774+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:33:02.792+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:33:02.792+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:33:02.804+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.086 seconds
[2022-12-15T12:33:33.680+0000] {processor.py:153} INFO - Started process (PID=13539) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:33:33.692+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:33:33.692+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:33:33.692+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:33:33.701+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:33:33.731+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:33:33.731+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:33:33.750+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:33:33.750+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:33:33.765+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.086 seconds
[2022-12-15T12:34:04.178+0000] {processor.py:153} INFO - Started process (PID=13619) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:34:04.190+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:34:04.190+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:34:04.190+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:34:04.198+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:34:04.223+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:34:04.223+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:34:04.242+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:34:04.242+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:34:04.255+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.079 seconds
[2022-12-15T12:34:34.604+0000] {processor.py:153} INFO - Started process (PID=13701) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:34:34.615+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:34:34.616+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:34:34.616+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:34:34.630+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:34:34.653+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:34:34.653+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:34:34.669+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:34:34.669+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:34:34.681+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.080 seconds
[2022-12-15T12:35:05.290+0000] {processor.py:153} INFO - Started process (PID=13789) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:35:05.302+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:35:05.303+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:35:05.303+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:35:05.315+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:35:05.342+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:35:05.342+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:35:05.363+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:35:05.363+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:35:05.378+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.091 seconds
[2022-12-15T12:35:36.076+0000] {processor.py:153} INFO - Started process (PID=13862) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:35:36.087+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:35:36.087+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:35:36.087+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:35:36.097+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:35:36.127+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:35:36.127+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:35:36.146+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:35:36.146+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:35:36.161+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.088 seconds
[2022-12-15T12:36:06.746+0000] {processor.py:153} INFO - Started process (PID=13949) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:36:06.757+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:36:06.758+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:36:06.758+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:36:06.769+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:36:06.794+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:36:06.794+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:36:06.816+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:36:06.816+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:36:06.834+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.090 seconds
[2022-12-15T12:36:37.178+0000] {processor.py:153} INFO - Started process (PID=14021) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:36:37.190+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:36:37.190+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:36:37.190+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:36:37.202+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:36:37.234+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:36:37.234+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:36:37.259+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:36:37.259+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:36:37.275+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.099 seconds
[2022-12-15T12:37:07.716+0000] {processor.py:153} INFO - Started process (PID=14109) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:37:07.727+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:37:07.728+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:37:07.728+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:37:07.742+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:37:07.782+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:37:07.781+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:37:07.803+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:37:07.802+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:37:07.818+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.104 seconds
[2022-12-15T12:37:17.919+0000] {processor.py:153} INFO - Started process (PID=14127) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:37:17.930+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:37:17.931+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:37:17.931+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:37:17.942+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:37:17.972+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:37:17.972+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:37:18.011+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:37:18.010+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:37:18.047+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.131 seconds
[2022-12-15T12:37:48.615+0000] {processor.py:153} INFO - Started process (PID=14198) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:37:48.617+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:37:48.617+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:37:48.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:37:48.627+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:37:48.660+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:37:48.660+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:37:48.719+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:37:48.719+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:37:48.747+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.135 seconds
[2022-12-15T12:38:19.261+0000] {processor.py:153} INFO - Started process (PID=14286) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:38:19.272+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:38:19.273+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:38:19.273+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:38:19.282+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:38:19.308+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:38:19.308+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:38:19.329+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:38:19.329+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:38:19.342+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.083 seconds
[2022-12-15T12:38:49.898+0000] {processor.py:153} INFO - Started process (PID=14358) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:38:49.910+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:38:49.910+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:38:49.910+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:38:49.922+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:38:49.951+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:38:49.951+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:38:49.971+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:38:49.971+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:38:49.985+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.090 seconds
[2022-12-15T12:39:20.128+0000] {processor.py:153} INFO - Started process (PID=14447) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:39:20.140+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:39:20.140+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:39:20.140+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:39:20.149+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:39:20.177+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:39:20.177+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:39:20.194+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:39:20.194+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:39:20.208+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T12:39:50.443+0000] {processor.py:153} INFO - Started process (PID=14535) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:39:50.455+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:39:50.455+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:39:50.455+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:39:50.468+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:39:50.493+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:39:50.493+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:39:50.511+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:39:50.511+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:39:50.526+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.085 seconds
[2022-12-15T12:40:20.859+0000] {processor.py:153} INFO - Started process (PID=14606) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:40:20.870+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:40:20.871+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:40:20.870+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:40:20.879+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:40:20.906+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:40:20.905+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:40:20.924+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:40:20.924+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:40:20.936+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.081 seconds
[2022-12-15T12:40:51.370+0000] {processor.py:153} INFO - Started process (PID=14693) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:40:51.371+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:40:51.371+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:40:51.371+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:40:51.381+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:40:51.409+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:40:51.409+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:40:51.430+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:40:51.430+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:40:51.442+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.075 seconds
[2022-12-15T12:41:21.582+0000] {processor.py:153} INFO - Started process (PID=14765) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:41:21.593+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:41:21.594+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:41:21.594+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:41:21.603+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:41:21.632+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:41:21.632+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:41:21.657+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:41:21.657+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:41:21.672+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.094 seconds
[2022-12-15T12:41:52.016+0000] {processor.py:153} INFO - Started process (PID=14853) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:41:52.027+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:41:52.027+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:41:52.027+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:41:52.038+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:41:52.067+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:41:52.067+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:41:52.085+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:41:52.085+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:41:52.097+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.084 seconds
[2022-12-15T12:42:22.396+0000] {processor.py:153} INFO - Started process (PID=14925) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:42:22.397+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:42:22.398+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:42:22.398+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:42:22.408+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:42:22.447+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:42:22.446+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:42:22.466+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:42:22.466+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:42:22.478+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.084 seconds
[2022-12-15T12:42:52.785+0000] {processor.py:153} INFO - Started process (PID=15013) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:42:52.796+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:42:52.796+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:42:52.796+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:42:52.806+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:42:52.836+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:42:52.836+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:42:52.854+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:42:52.854+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:42:52.869+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.087 seconds
[2022-12-15T12:43:23.301+0000] {processor.py:153} INFO - Started process (PID=15085) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:43:23.313+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:43:23.313+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:43:23.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:43:23.323+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:43:23.350+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:43:23.350+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:43:23.368+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:43:23.368+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:43:23.381+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T12:43:53.486+0000] {processor.py:153} INFO - Started process (PID=15173) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:43:53.497+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:43:53.498+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:43:53.497+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:43:53.508+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:43:53.534+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:43:53.533+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:43:53.553+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:43:53.553+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:43:53.566+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.083 seconds
[2022-12-15T12:44:23.834+0000] {processor.py:153} INFO - Started process (PID=15255) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:44:23.845+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:44:23.846+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:44:23.846+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:44:23.855+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:44:23.885+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:44:23.884+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:44:23.904+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:44:23.904+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:44:23.917+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.084 seconds
[2022-12-15T12:44:54.194+0000] {processor.py:153} INFO - Started process (PID=15332) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:44:54.205+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:44:54.205+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:44:54.205+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:44:54.214+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:44:54.243+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:44:54.243+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:44:54.267+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:44:54.267+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:44:54.283+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.091 seconds
[2022-12-15T12:45:24.643+0000] {processor.py:153} INFO - Started process (PID=15420) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:45:24.644+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:45:24.644+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:45:24.644+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:45:24.655+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:45:24.684+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:45:24.684+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:45:24.701+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:45:24.701+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:45:24.715+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.075 seconds
[2022-12-15T12:45:54.886+0000] {processor.py:153} INFO - Started process (PID=15492) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:45:54.887+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:45:54.887+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:45:54.887+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:45:54.897+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:45:54.926+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:45:54.926+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:45:54.945+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:45:54.945+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:45:54.958+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.074 seconds
[2022-12-15T12:46:25.228+0000] {processor.py:153} INFO - Started process (PID=15580) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:46:25.239+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:46:25.239+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:46:25.239+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:46:25.249+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:46:25.278+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:46:25.278+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:46:25.297+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:46:25.297+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:46:25.312+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.086 seconds
[2022-12-15T12:46:55.838+0000] {processor.py:153} INFO - Started process (PID=15652) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:46:55.849+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:46:55.850+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:46:55.850+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:46:55.863+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:46:55.900+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:46:55.899+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:46:55.927+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:46:55.926+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:46:55.944+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.108 seconds
[2022-12-15T12:47:26.475+0000] {processor.py:153} INFO - Started process (PID=15740) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:47:26.486+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:47:26.486+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:47:26.486+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:47:26.497+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:47:26.523+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:47:26.523+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:47:26.540+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:47:26.540+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:47:26.553+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.080 seconds
[2022-12-15T12:47:56.927+0000] {processor.py:153} INFO - Started process (PID=15811) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:47:56.939+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:47:56.939+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:47:56.939+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:47:56.949+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:47:56.975+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:47:56.975+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:47:56.994+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:47:56.994+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:47:57.006+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.080 seconds
[2022-12-15T12:48:27.425+0000] {processor.py:153} INFO - Started process (PID=15899) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:48:27.436+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:48:27.437+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:48:27.437+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:48:27.447+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:48:27.475+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:48:27.475+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:48:27.495+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:48:27.494+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:48:27.507+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.084 seconds
[2022-12-15T12:48:57.743+0000] {processor.py:153} INFO - Started process (PID=15986) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:48:57.754+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:48:57.754+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:48:57.754+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:48:57.764+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:48:57.792+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:48:57.792+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:48:57.809+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:48:57.809+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:48:57.821+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.080 seconds
[2022-12-15T12:49:28.126+0000] {processor.py:153} INFO - Started process (PID=16058) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:49:28.137+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:49:28.138+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:49:28.137+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:49:28.148+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:49:28.175+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:49:28.175+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:49:28.194+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:49:28.194+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:49:28.211+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.088 seconds
[2022-12-15T12:49:58.509+0000] {processor.py:153} INFO - Started process (PID=16146) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:49:58.521+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:49:58.521+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:49:58.521+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:49:58.533+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:49:58.562+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:49:58.561+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:49:58.583+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:49:58.583+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:49:58.601+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.093 seconds
[2022-12-15T12:50:28.784+0000] {processor.py:153} INFO - Started process (PID=16218) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:50:28.785+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:50:28.785+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:50:28.785+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:50:28.795+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:50:28.824+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:50:28.823+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:50:28.845+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:50:28.844+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:50:28.863+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T12:50:59.367+0000] {processor.py:153} INFO - Started process (PID=16306) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:50:59.378+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:50:59.379+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:50:59.379+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:50:59.388+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:50:59.413+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:50:59.413+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:50:59.431+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:50:59.431+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:50:59.443+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.079 seconds
[2022-12-15T12:51:29.853+0000] {processor.py:153} INFO - Started process (PID=16378) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:51:29.864+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:51:29.864+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:51:29.864+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:51:29.873+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:51:29.903+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:51:29.903+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:51:29.921+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:51:29.921+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:51:29.933+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.083 seconds
[2022-12-15T12:52:00.159+0000] {processor.py:153} INFO - Started process (PID=16466) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:52:00.160+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:52:00.161+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:52:00.161+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:52:00.172+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:52:00.203+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:52:00.203+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:52:00.222+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:52:00.221+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:52:00.234+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.077 seconds
[2022-12-15T12:52:30.627+0000] {processor.py:153} INFO - Started process (PID=16538) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:52:30.638+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:52:30.639+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:52:30.638+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:52:30.649+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:52:30.675+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:52:30.675+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:52:30.694+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:52:30.694+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:52:30.707+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T12:53:00.948+0000] {processor.py:153} INFO - Started process (PID=16626) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:53:00.959+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:53:00.959+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:53:00.959+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:53:00.969+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:53:00.995+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:53:00.995+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:53:01.015+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:53:01.014+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:53:01.030+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.084 seconds
[2022-12-15T12:53:31.491+0000] {processor.py:153} INFO - Started process (PID=16714) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:53:31.497+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:53:31.498+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:53:31.498+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:53:31.512+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:53:31.552+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:53:31.551+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:53:31.572+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:53:31.572+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:53:31.588+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.099 seconds
[2022-12-15T12:54:01.790+0000] {processor.py:153} INFO - Started process (PID=16785) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:54:01.793+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:54:01.794+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:54:01.794+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:54:01.805+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:54:01.833+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:54:01.833+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:54:01.853+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:54:01.853+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:54:01.867+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.078 seconds
[2022-12-15T12:54:32.291+0000] {processor.py:153} INFO - Started process (PID=16874) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:54:32.302+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:54:32.302+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:54:32.302+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:54:32.313+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:54:32.340+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:54:32.340+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:54:32.358+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:54:32.358+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:54:32.370+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T12:55:02.442+0000] {processor.py:153} INFO - Started process (PID=16946) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:55:02.442+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:55:02.443+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:55:02.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:55:02.453+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:55:02.484+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:55:02.484+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:55:02.511+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:55:02.510+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:55:02.530+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.091 seconds
[2022-12-15T12:55:33.136+0000] {processor.py:153} INFO - Started process (PID=17034) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:55:33.147+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:55:33.148+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:55:33.147+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:55:33.157+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:55:33.183+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:55:33.183+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:55:33.201+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:55:33.201+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:55:33.214+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T12:56:03.464+0000] {processor.py:153} INFO - Started process (PID=17105) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:56:03.475+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:56:03.476+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:56:03.476+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:56:03.485+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:56:03.513+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:56:03.512+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:56:03.531+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:56:03.530+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:56:03.543+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.083 seconds
[2022-12-15T12:56:33.986+0000] {processor.py:153} INFO - Started process (PID=17193) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:56:33.997+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:56:33.998+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:56:33.997+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:56:34.007+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:56:34.033+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:56:34.033+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:56:34.053+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:56:34.052+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:56:34.064+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T12:57:04.290+0000] {processor.py:153} INFO - Started process (PID=17266) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:57:04.302+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:57:04.302+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:57:04.302+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:57:04.312+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:57:04.351+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:57:04.351+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:57:04.370+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:57:04.370+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:57:04.387+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.099 seconds
[2022-12-15T12:57:34.679+0000] {processor.py:153} INFO - Started process (PID=17356) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:57:34.680+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:57:34.681+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:57:34.681+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:57:34.691+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:57:34.718+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:57:34.718+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:57:34.739+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:57:34.738+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:57:34.751+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.075 seconds
[2022-12-15T12:58:04.975+0000] {processor.py:153} INFO - Started process (PID=17445) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:58:04.986+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:58:04.987+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:58:04.986+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:58:05.000+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:58:05.036+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:58:05.036+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:58:05.062+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:58:05.062+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:58:05.079+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.107 seconds
[2022-12-15T12:58:35.501+0000] {processor.py:153} INFO - Started process (PID=17517) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:58:35.513+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:58:35.513+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:58:35.513+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:58:35.522+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:58:35.550+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:58:35.550+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:58:35.575+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:58:35.575+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:58:35.588+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.089 seconds
[2022-12-15T12:59:05.824+0000] {processor.py:153} INFO - Started process (PID=17605) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:59:05.835+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:59:05.835+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:59:05.835+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:59:05.844+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:59:05.872+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:59:05.872+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:59:05.890+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:59:05.890+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:59:05.907+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.086 seconds
[2022-12-15T12:59:36.119+0000] {processor.py:153} INFO - Started process (PID=17677) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:59:36.130+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T12:59:36.131+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:59:36.130+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:59:36.143+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T12:59:36.177+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:59:36.177+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T12:59:36.197+0000] {logging_mixin.py:137} INFO - [2022-12-15T12:59:36.197+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T12:59:36.210+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.093 seconds
[2022-12-15T13:00:06.598+0000] {processor.py:153} INFO - Started process (PID=17765) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:00:06.609+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:00:06.610+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:00:06.610+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:00:06.619+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:00:06.648+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:00:06.648+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:00:06.667+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:00:06.667+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:00:06.679+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.083 seconds
[2022-12-15T13:00:37.007+0000] {processor.py:153} INFO - Started process (PID=17837) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:00:37.018+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:00:37.019+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:00:37.018+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:00:37.028+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:00:37.055+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:00:37.055+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:00:37.072+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:00:37.072+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:00:37.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T13:01:07.184+0000] {processor.py:153} INFO - Started process (PID=17925) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:01:07.195+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:01:07.196+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:01:07.196+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:01:07.205+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:01:07.230+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:01:07.230+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:01:07.247+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:01:07.247+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:01:07.261+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.081 seconds
[2022-12-15T13:01:37.473+0000] {processor.py:153} INFO - Started process (PID=18003) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:01:37.484+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:01:37.485+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:01:37.485+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:01:37.494+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:01:37.527+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:01:37.527+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:01:37.550+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:01:37.550+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:01:37.564+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.093 seconds
[2022-12-15T13:02:07.827+0000] {processor.py:153} INFO - Started process (PID=18084) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:02:07.838+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:02:07.838+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:02:07.838+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:02:07.849+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:02:07.879+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:02:07.879+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:02:07.897+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:02:07.897+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:02:07.911+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.087 seconds
[2022-12-15T13:02:38.244+0000] {processor.py:153} INFO - Started process (PID=18172) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:02:38.256+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:02:38.256+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:02:38.256+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:02:38.265+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:02:38.292+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:02:38.292+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:02:38.316+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:02:38.316+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:02:38.331+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.089 seconds
[2022-12-15T13:03:08.481+0000] {processor.py:153} INFO - Started process (PID=18244) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:03:08.482+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:03:08.483+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:03:08.483+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:03:08.492+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:03:08.518+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:03:08.518+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:03:08.539+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:03:08.538+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:03:08.554+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.076 seconds
[2022-12-15T13:03:38.850+0000] {processor.py:153} INFO - Started process (PID=18331) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:03:38.851+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:03:38.852+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:03:38.852+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:03:38.861+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:03:38.889+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:03:38.889+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:03:38.905+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:03:38.905+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:03:38.916+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.068 seconds
[2022-12-15T13:04:09.042+0000] {processor.py:153} INFO - Started process (PID=18404) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:04:09.053+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:04:09.054+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:04:09.054+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:04:09.063+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:04:09.091+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:04:09.091+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:04:09.114+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:04:09.114+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:04:09.127+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.088 seconds
[2022-12-15T13:04:39.460+0000] {processor.py:153} INFO - Started process (PID=18492) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:04:39.461+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:04:39.461+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:04:39.461+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:04:39.470+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:04:39.497+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:04:39.497+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:04:39.514+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:04:39.514+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:04:39.527+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.070 seconds
[2022-12-15T13:05:09.607+0000] {processor.py:153} INFO - Started process (PID=18564) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:05:09.607+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:05:09.607+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:05:09.607+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:05:09.616+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:05:09.642+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:05:09.642+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:05:09.663+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:05:09.663+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:05:09.675+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.071 seconds
[2022-12-15T13:05:39.915+0000] {processor.py:153} INFO - Started process (PID=18651) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:05:39.926+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:05:39.927+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:05:39.927+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:05:39.936+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:05:39.966+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:05:39.966+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:05:39.991+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:05:39.990+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:05:40.006+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.094 seconds
[2022-12-15T13:06:10.308+0000] {processor.py:153} INFO - Started process (PID=18724) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:06:10.319+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:06:10.320+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:06:10.320+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:06:10.331+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:06:10.361+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:06:10.361+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:06:10.380+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:06:10.380+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:06:10.397+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.092 seconds
[2022-12-15T13:06:40.569+0000] {processor.py:153} INFO - Started process (PID=18811) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:06:40.569+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:06:40.570+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:06:40.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:06:40.581+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:06:40.610+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:06:40.610+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:06:40.630+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:06:40.630+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:06:40.649+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T13:07:10.891+0000] {processor.py:153} INFO - Started process (PID=18890) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:07:10.903+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:07:10.904+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:07:10.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:07:10.913+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:07:10.941+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:07:10.941+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:07:10.960+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:07:10.960+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:07:10.974+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.086 seconds
[2022-12-15T13:07:41.206+0000] {processor.py:153} INFO - Started process (PID=18971) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:07:41.218+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:07:41.218+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:07:41.218+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:07:41.227+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:07:41.255+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:07:41.255+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:07:41.272+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:07:41.272+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:07:41.286+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T13:08:11.540+0000] {processor.py:153} INFO - Started process (PID=19059) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:08:11.551+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:08:11.552+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:08:11.552+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:08:11.561+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:08:11.590+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:08:11.590+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:08:11.610+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:08:11.610+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:08:11.623+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.085 seconds
[2022-12-15T13:08:41.879+0000] {processor.py:153} INFO - Started process (PID=19131) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:08:41.891+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:08:41.892+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:08:41.892+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:08:41.900+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:08:41.926+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:08:41.925+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:08:41.951+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:08:41.951+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:08:41.967+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.090 seconds
[2022-12-15T13:09:12.434+0000] {processor.py:153} INFO - Started process (PID=19219) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:09:12.445+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:09:12.446+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:09:12.446+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:09:12.455+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:09:12.481+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:09:12.481+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:09:12.501+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:09:12.501+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:09:12.513+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T13:09:42.938+0000] {processor.py:153} INFO - Started process (PID=19290) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:09:42.949+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:09:42.949+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:09:42.949+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:09:42.961+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:09:42.986+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:09:42.986+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:09:43.003+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:09:43.003+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:09:43.019+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.084 seconds
[2022-12-15T13:10:13.277+0000] {processor.py:153} INFO - Started process (PID=19377) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:10:13.277+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:10:13.278+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:10:13.278+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:10:13.287+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:10:13.314+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:10:13.314+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:10:13.333+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:10:13.333+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:10:13.347+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.072 seconds
[2022-12-15T13:10:43.699+0000] {processor.py:153} INFO - Started process (PID=19449) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:10:43.701+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:10:43.702+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:10:43.701+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:10:43.713+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:10:43.743+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:10:43.743+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:10:43.762+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:10:43.762+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:10:43.776+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.080 seconds
[2022-12-15T13:11:13.975+0000] {processor.py:153} INFO - Started process (PID=19537) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:11:13.976+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:11:13.976+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:11:13.976+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:11:13.987+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:11:14.022+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:11:14.022+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:11:14.048+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:11:14.048+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:11:14.066+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.093 seconds
[2022-12-15T13:11:44.248+0000] {processor.py:153} INFO - Started process (PID=19618) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:11:44.259+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:11:44.260+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:11:44.260+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:11:44.270+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:11:44.304+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:11:44.303+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:11:44.330+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:11:44.330+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:11:44.347+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.101 seconds
[2022-12-15T13:12:14.770+0000] {processor.py:153} INFO - Started process (PID=19697) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:12:14.781+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:12:14.782+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:12:14.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:12:14.791+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:12:14.817+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:12:14.817+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:12:14.834+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:12:14.834+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:12:14.849+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.082 seconds
[2022-12-15T13:12:45.066+0000] {processor.py:153} INFO - Started process (PID=19785) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:12:45.077+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:12:45.077+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:12:45.077+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:12:45.089+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:12:45.118+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:12:45.118+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:12:45.141+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:12:45.141+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:12:45.153+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.091 seconds
[2022-12-15T13:13:15.400+0000] {processor.py:153} INFO - Started process (PID=19857) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:13:15.411+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:13:15.411+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:13:15.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:13:15.420+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:13:15.455+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:13:15.455+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:13:15.476+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:13:15.476+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:13:15.491+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.094 seconds
[2022-12-15T13:13:45.928+0000] {processor.py:153} INFO - Started process (PID=19945) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:13:45.939+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:13:45.940+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:13:45.940+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:13:45.949+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:13:45.975+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:13:45.975+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:13:45.994+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:13:45.993+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:13:46.006+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.081 seconds
[2022-12-15T13:14:16.116+0000] {processor.py:153} INFO - Started process (PID=20018) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:14:16.127+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:14:16.128+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:14:16.128+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:14:16.137+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:14:16.165+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:14:16.165+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:14:16.185+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:14:16.185+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:14:16.202+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.088 seconds
[2022-12-15T13:14:46.509+0000] {processor.py:153} INFO - Started process (PID=20106) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:14:46.520+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:14:46.521+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:14:46.521+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:14:46.533+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:14:46.563+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:14:46.563+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:14:46.584+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:14:46.584+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:14:46.598+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.093 seconds
[2022-12-15T13:15:16.858+0000] {processor.py:153} INFO - Started process (PID=20179) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:15:16.869+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:15:16.870+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:15:16.870+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:15:16.880+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:15:16.908+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:15:16.907+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:15:16.927+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:15:16.927+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:15:16.941+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.086 seconds
[2022-12-15T13:15:47.218+0000] {processor.py:153} INFO - Started process (PID=20269) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:15:47.219+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:15:47.220+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:15:47.220+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:15:47.229+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:15:47.257+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:15:47.256+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:15:47.274+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:15:47.274+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:15:47.288+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.073 seconds
[2022-12-15T13:16:17.410+0000] {processor.py:153} INFO - Started process (PID=20341) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:16:17.421+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:16:17.422+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:16:17.421+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:16:17.431+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:16:17.464+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:16:17.464+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:16:17.491+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:16:17.491+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:16:17.507+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.099 seconds
[2022-12-15T13:16:47.655+0000] {processor.py:153} INFO - Started process (PID=20429) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:16:47.667+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:16:47.667+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:16:47.667+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:16:47.677+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:16:47.704+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:16:47.704+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:16:47.722+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:16:47.722+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:16:47.734+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.081 seconds
[2022-12-15T13:17:18.044+0000] {processor.py:153} INFO - Started process (PID=20516) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:17:18.055+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:17:18.056+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:17:18.056+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:17:18.065+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:17:18.092+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:17:18.092+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:17:18.109+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:17:18.109+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:17:18.121+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.079 seconds
[2022-12-15T13:17:48.407+0000] {processor.py:153} INFO - Started process (PID=20588) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:17:48.418+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:17:48.419+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:17:48.418+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:17:48.427+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:17:48.457+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:17:48.456+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:17:48.476+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:17:48.476+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:17:48.492+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.087 seconds
[2022-12-15T13:18:18.956+0000] {processor.py:153} INFO - Started process (PID=20676) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:18:18.967+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:18:18.968+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:18:18.968+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:18:18.978+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:18:19.007+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:18:19.007+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:18:19.028+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:18:19.028+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:18:19.042+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.089 seconds
[2022-12-15T13:18:49.480+0000] {processor.py:153} INFO - Started process (PID=20748) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:18:49.491+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:18:49.492+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:18:49.492+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:18:49.503+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:18:49.536+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:18:49.536+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:18:49.555+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:18:49.555+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:18:49.569+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.091 seconds
[2022-12-15T13:19:20.088+0000] {processor.py:153} INFO - Started process (PID=20836) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:19:20.089+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:19:20.090+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:19:20.090+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:19:20.100+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:19:20.128+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:19:20.128+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:19:20.146+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:19:20.146+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:19:20.161+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.075 seconds
[2022-12-15T13:19:50.659+0000] {processor.py:153} INFO - Started process (PID=20908) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:19:50.670+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:19:50.671+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:19:50.671+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:19:50.683+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:19:50.712+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:19:50.712+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:19:50.736+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:19:50.736+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:19:50.752+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.096 seconds
[2022-12-15T13:20:21.056+0000] {processor.py:153} INFO - Started process (PID=20996) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:20:21.067+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:20:21.068+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:20:21.068+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:20:21.080+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:20:21.108+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:20:21.108+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:20:21.130+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:20:21.130+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:20:21.143+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.090 seconds
[2022-12-15T13:20:51.491+0000] {processor.py:153} INFO - Started process (PID=21068) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:20:51.502+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:20:51.503+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:20:51.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:20:51.514+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:20:51.543+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:20:51.543+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:20:51.562+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:20:51.562+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:20:51.576+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.087 seconds
[2022-12-15T13:21:21.905+0000] {processor.py:153} INFO - Started process (PID=21156) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:21:21.916+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:21:21.917+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:21:21.917+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:21:21.930+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:21:21.964+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:21:21.964+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:21:21.990+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:21:21.990+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:21:22.007+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.105 seconds
[2022-12-15T13:21:52.542+0000] {processor.py:153} INFO - Started process (PID=21237) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:21:52.553+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:21:52.554+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:21:52.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:21:52.563+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:21:52.591+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:21:52.591+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:21:52.611+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:21:52.611+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:21:52.625+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.085 seconds
[2022-12-15T13:22:22.969+0000] {processor.py:153} INFO - Started process (PID=21316) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:22:22.980+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:22:22.981+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:22:22.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:22:22.991+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:22:23.020+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:22:23.020+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:22:23.042+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:22:23.042+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:22:23.056+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.089 seconds
[2022-12-15T13:22:53.465+0000] {processor.py:153} INFO - Started process (PID=21404) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:22:53.477+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:22:53.477+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:22:53.477+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:22:53.486+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:22:53.515+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:22:53.515+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:22:53.534+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:22:53.534+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:22:53.548+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.085 seconds
[2022-12-15T13:23:23.827+0000] {processor.py:153} INFO - Started process (PID=21476) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:23:23.838+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:23:23.839+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:23:23.839+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:23:23.848+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:23:23.878+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:23:23.878+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:23:23.898+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:23:23.898+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:23:23.916+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.091 seconds
[2022-12-15T13:23:54.495+0000] {processor.py:153} INFO - Started process (PID=21563) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:23:54.495+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:23:54.496+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:23:54.496+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:23:54.507+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:23:54.537+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:23:54.536+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:23:54.556+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:23:54.556+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:23:54.572+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.080 seconds
[2022-12-15T13:24:25.112+0000] {processor.py:153} INFO - Started process (PID=21635) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:24:25.123+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:24:25.123+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:24:25.123+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:24:25.134+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:24:25.171+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:24:25.171+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:24:25.199+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:24:25.199+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:24:25.217+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.109 seconds
[2022-12-15T13:24:55.688+0000] {processor.py:153} INFO - Started process (PID=21722) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:24:55.699+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:24:55.700+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:24:55.700+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:24:55.710+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:24:55.743+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:24:55.743+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:24:55.765+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:24:55.765+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:24:55.779+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.094 seconds
[2022-12-15T13:25:26.387+0000] {processor.py:153} INFO - Started process (PID=21794) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:25:26.398+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:25:26.398+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:25:26.398+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:25:26.407+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:25:26.437+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:25:26.437+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:25:26.457+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:25:26.456+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:25:26.471+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.087 seconds
[2022-12-15T13:25:57.031+0000] {processor.py:153} INFO - Started process (PID=21882) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:25:57.031+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:25:57.032+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:25:57.032+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:25:57.042+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:25:57.071+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:25:57.071+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:25:57.091+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:25:57.091+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:25:57.104+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.077 seconds
[2022-12-15T13:26:27.334+0000] {processor.py:153} INFO - Started process (PID=21953) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:26:27.345+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:26:27.346+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:26:27.346+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:26:27.355+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:26:27.384+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:26:27.384+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:26:27.406+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:26:27.405+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:26:27.420+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.088 seconds
[2022-12-15T13:26:57.787+0000] {processor.py:153} INFO - Started process (PID=22040) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:26:57.798+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:26:57.798+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:26:57.798+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:26:57.811+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:26:57.841+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:26:57.841+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:26:57.861+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:26:57.861+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:26:57.874+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.090 seconds
[2022-12-15T13:27:28.467+0000] {processor.py:153} INFO - Started process (PID=22113) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:27:28.478+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:27:28.479+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:27:28.479+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:27:28.490+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:27:28.517+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:27:28.517+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:27:28.536+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:27:28.536+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:27:28.549+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.085 seconds
[2022-12-15T13:27:58.972+0000] {processor.py:153} INFO - Started process (PID=22202) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:27:58.983+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:27:58.983+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:27:58.983+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:27:58.998+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:27:59.025+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:27:59.025+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:27:59.045+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:27:59.045+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:27:59.057+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.089 seconds
[2022-12-15T13:28:29.406+0000] {processor.py:153} INFO - Started process (PID=22276) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:28:29.417+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:28:29.418+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:28:29.418+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:28:29.427+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:28:29.464+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:28:29.464+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:28:29.496+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:28:29.496+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:28:29.526+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.124 seconds
[2022-12-15T13:28:59.861+0000] {processor.py:153} INFO - Started process (PID=22364) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:28:59.862+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:28:59.862+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:28:59.862+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:28:59.871+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:28:59.900+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:28:59.899+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:28:59.918+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:28:59.918+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:28:59.933+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.074 seconds
[2022-12-15T13:29:30.419+0000] {processor.py:153} INFO - Started process (PID=22453) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:29:30.425+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:29:30.425+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:29:30.425+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:29:30.459+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:29:30.491+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:29:30.491+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:29:30.509+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:29:30.509+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:29:30.526+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.111 seconds
[2022-12-15T13:30:00.950+0000] {processor.py:153} INFO - Started process (PID=22526) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:30:00.961+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:30:00.962+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:30:00.962+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:30:00.974+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:30:01.002+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:30:01.001+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:30:01.025+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:30:01.025+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:30:01.037+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.090 seconds
[2022-12-15T13:30:31.424+0000] {processor.py:153} INFO - Started process (PID=22615) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:30:31.435+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:30:31.435+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:30:31.435+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:30:31.445+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:30:31.475+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:30:31.475+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:30:31.494+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:30:31.494+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:30:31.507+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.086 seconds
[2022-12-15T13:31:01.895+0000] {processor.py:153} INFO - Started process (PID=22689) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:31:01.895+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:31:01.896+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:31:01.896+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:31:01.910+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:31:01.941+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:31:01.941+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:31:01.968+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:31:01.968+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:31:01.984+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.092 seconds
[2022-12-15T13:31:32.622+0000] {processor.py:153} INFO - Started process (PID=22778) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:31:32.623+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:31:32.623+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:31:32.623+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:31:32.635+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:31:32.670+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:31:32.670+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:31:32.691+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:31:32.691+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:31:32.707+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.088 seconds
[2022-12-15T13:32:02.846+0000] {processor.py:153} INFO - Started process (PID=22851) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:32:02.857+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:32:02.857+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:32:02.857+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:32:02.868+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:32:02.895+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:32:02.894+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:32:02.921+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:32:02.921+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:32:02.936+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.093 seconds
[2022-12-15T13:32:10.921+0000] {processor.py:153} INFO - Started process (PID=22906) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:32:10.932+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:32:10.933+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:32:10.933+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:32:10.942+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:32:11.001+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:32:11.001+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:32:11.016+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:32:11.016+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:32:11.031+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.113 seconds
[2022-12-15T13:32:41.614+0000] {processor.py:153} INFO - Started process (PID=22979) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:32:41.615+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:32:41.616+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:32:41.616+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:32:41.627+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:32:41.656+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:32:41.656+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:32:41.675+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:32:41.675+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:32:41.688+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.078 seconds
[2022-12-15T13:33:12.136+0000] {processor.py:153} INFO - Started process (PID=23068) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:33:12.147+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:33:12.147+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:33:12.147+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:33:12.157+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:33:12.189+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:33:12.189+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:33:12.207+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:33:12.207+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:33:12.220+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.087 seconds
[2022-12-15T13:33:42.471+0000] {processor.py:153} INFO - Started process (PID=23141) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:33:42.482+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:33:42.483+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:33:42.483+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:33:42.495+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:33:42.522+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:33:42.522+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:33:42.539+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:33:42.539+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:33:42.554+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.085 seconds
[2022-12-15T13:34:12.965+0000] {processor.py:153} INFO - Started process (PID=23230) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:34:12.976+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:34:12.977+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:34:12.977+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:34:12.986+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:34:13.018+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:34:13.017+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:34:13.037+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:34:13.037+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:34:13.050+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.087 seconds
[2022-12-15T13:34:43.667+0000] {processor.py:153} INFO - Started process (PID=23320) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:34:43.668+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:34:43.668+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:34:43.668+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:34:43.677+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:34:43.707+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:34:43.707+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:34:43.724+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:34:43.724+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:34:43.740+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.075 seconds
[2022-12-15T13:35:14.151+0000] {processor.py:153} INFO - Started process (PID=23393) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:35:14.162+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:35:14.163+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:35:14.163+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:35:14.176+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:35:14.207+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:35:14.207+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:35:14.227+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:35:14.226+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:35:14.242+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.093 seconds
[2022-12-15T13:35:44.560+0000] {processor.py:153} INFO - Started process (PID=23482) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:35:44.571+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:35:44.572+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:35:44.572+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:35:44.583+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:35:44.618+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:35:44.618+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:35:44.638+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:35:44.638+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:35:44.658+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.100 seconds
[2022-12-15T13:36:15.040+0000] {processor.py:153} INFO - Started process (PID=23555) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:36:15.052+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:36:15.053+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:36:15.053+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:36:15.064+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:36:15.093+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:36:15.093+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:36:15.110+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:36:15.110+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:36:15.123+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.087 seconds
[2022-12-15T13:36:45.436+0000] {processor.py:153} INFO - Started process (PID=23643) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:36:45.436+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:36:45.437+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:36:45.437+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:36:45.446+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:36:45.477+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:36:45.476+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:36:45.496+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:36:45.496+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:36:45.508+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.075 seconds
[2022-12-15T13:37:15.927+0000] {processor.py:153} INFO - Started process (PID=23716) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:37:15.939+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:37:15.940+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:37:15.940+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:37:15.954+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:37:15.980+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:37:15.980+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:37:15.999+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:37:15.999+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:37:16.013+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.090 seconds
[2022-12-15T13:37:46.458+0000] {processor.py:153} INFO - Started process (PID=23806) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:37:46.470+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:37:46.471+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:37:46.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:37:46.485+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:37:46.513+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:37:46.513+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:37:46.531+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:37:46.531+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:37:46.543+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.089 seconds
[2022-12-15T13:38:17.146+0000] {processor.py:153} INFO - Started process (PID=23879) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:38:17.157+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:38:17.159+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:38:17.158+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:38:17.174+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:38:17.202+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:38:17.202+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:38:17.218+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:38:17.218+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:38:17.233+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.091 seconds
[2022-12-15T13:38:19.261+0000] {processor.py:153} INFO - Started process (PID=23880) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:38:19.262+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:38:19.263+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:38:19.263+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:38:19.269+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:38:19.269+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 114, in <module>
    @task
NameError: name 'task' is not defined
[2022-12-15T13:38:19.270+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:38:19.284+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.027 seconds
[2022-12-15T13:38:49.748+0000] {processor.py:153} INFO - Started process (PID=23969) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:38:49.760+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:38:49.761+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:38:49.761+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:38:49.781+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:38:49.780+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:38:49.782+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:38:49.794+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.050 seconds
[2022-12-15T13:39:20.129+0000] {processor.py:153} INFO - Started process (PID=24042) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:39:20.141+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:39:20.142+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:39:20.142+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:39:20.164+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:39:20.163+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:39:20.164+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:39:20.177+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.051 seconds
[2022-12-15T13:39:50.802+0000] {processor.py:153} INFO - Started process (PID=24130) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:39:50.802+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:39:50.803+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:39:50.803+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:39:50.816+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:39:50.815+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:39:50.816+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:39:50.828+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.029 seconds
[2022-12-15T13:40:21.197+0000] {processor.py:153} INFO - Started process (PID=24210) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:40:21.208+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:40:21.208+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:40:21.208+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:40:21.220+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:40:21.219+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:40:21.220+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:40:21.231+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.036 seconds
[2022-12-15T13:40:51.793+0000] {processor.py:153} INFO - Started process (PID=24292) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:40:51.805+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:40:51.806+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:40:51.806+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:40:51.826+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:40:51.826+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:40:51.827+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:40:51.839+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.049 seconds
[2022-12-15T13:41:22.065+0000] {processor.py:153} INFO - Started process (PID=24383) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:41:22.076+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:41:22.077+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:41:22.077+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:41:22.090+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:41:22.089+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:41:22.090+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:41:22.105+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.043 seconds
[2022-12-15T13:41:52.703+0000] {processor.py:153} INFO - Started process (PID=24456) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:41:52.714+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:41:52.715+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:41:52.715+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:41:52.735+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:41:52.734+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:41:52.735+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:41:52.748+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.046 seconds
[2022-12-15T13:42:23.069+0000] {processor.py:153} INFO - Started process (PID=24545) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:42:23.081+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:42:23.082+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:42:23.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:42:23.099+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:42:23.099+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:42:23.100+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:42:23.116+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.048 seconds
[2022-12-15T13:42:53.272+0000] {processor.py:153} INFO - Started process (PID=24618) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:42:53.274+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:42:53.275+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:42:53.274+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:42:53.291+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:42:53.290+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:42:53.291+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:42:53.306+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.037 seconds
[2022-12-15T13:43:23.412+0000] {processor.py:153} INFO - Started process (PID=24691) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:43:23.424+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:43:23.425+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:43:23.425+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:43:23.443+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:43:23.442+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:43:23.443+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:43:23.504+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.094 seconds
[2022-12-15T13:43:53.643+0000] {processor.py:153} INFO - Started process (PID=24780) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:43:53.644+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:43:53.645+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:43:53.645+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:43:53.666+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:43:53.665+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:43:53.666+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:43:53.678+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.038 seconds
[2022-12-15T13:44:23.963+0000] {processor.py:153} INFO - Started process (PID=24853) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:44:23.974+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:44:23.975+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:44:23.975+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:44:23.987+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:44:23.986+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:44:23.987+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:44:23.999+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.038 seconds
[2022-12-15T13:44:54.294+0000] {processor.py:153} INFO - Started process (PID=24942) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:44:54.295+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:44:54.295+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:44:54.295+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:44:54.310+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:44:54.309+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:44:54.310+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:44:54.323+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.031 seconds
[2022-12-15T13:45:25.065+0000] {processor.py:153} INFO - Started process (PID=25014) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:45:25.077+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:45:25.078+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:45:25.078+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:45:25.095+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:45:25.093+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:45:25.095+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:45:25.108+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.046 seconds
[2022-12-15T13:45:55.731+0000] {processor.py:153} INFO - Started process (PID=25103) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:45:55.742+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:45:55.742+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:45:55.742+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:45:55.755+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:45:55.754+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:45:55.755+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:45:55.766+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.038 seconds
[2022-12-15T13:46:25.883+0000] {processor.py:153} INFO - Started process (PID=25176) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:46:25.894+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:46:25.895+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:46:25.895+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:46:25.913+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:46:25.913+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:46:25.914+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:46:25.927+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.048 seconds
[2022-12-15T13:46:56.006+0000] {processor.py:153} INFO - Started process (PID=25265) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:46:56.007+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:46:56.008+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:46:56.008+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:46:56.031+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:46:56.030+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:46:56.032+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:46:56.051+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.050 seconds
[2022-12-15T13:47:26.188+0000] {processor.py:153} INFO - Started process (PID=25338) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:47:26.199+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:47:26.200+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:47:26.200+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:47:26.218+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:47:26.217+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:47:26.218+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:47:26.234+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.050 seconds
[2022-12-15T13:47:56.390+0000] {processor.py:153} INFO - Started process (PID=25427) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:47:56.391+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:47:56.392+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:47:56.392+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:47:56.420+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:47:56.418+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:47:56.422+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:47:56.451+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.064 seconds
[2022-12-15T13:48:26.767+0000] {processor.py:153} INFO - Started process (PID=25500) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:48:26.768+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:48:26.768+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:48:26.768+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:48:26.783+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:48:26.783+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:48:26.783+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:48:26.800+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.037 seconds
[2022-12-15T13:48:57.056+0000] {processor.py:153} INFO - Started process (PID=25579) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:48:57.067+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:48:57.068+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:48:57.068+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:48:57.094+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:48:57.093+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:48:57.094+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:48:57.122+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.072 seconds
[2022-12-15T13:49:28.026+0000] {processor.py:153} INFO - Started process (PID=25661) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:49:28.037+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:49:28.037+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:49:28.037+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:49:28.056+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:49:28.055+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:49:28.056+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:49:28.069+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.046 seconds
[2022-12-15T13:49:58.300+0000] {processor.py:153} INFO - Started process (PID=25735) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:49:58.311+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:49:58.312+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:49:58.312+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:49:58.328+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:49:58.327+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:49:58.329+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:49:58.342+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.045 seconds
[2022-12-15T13:50:29.288+0000] {processor.py:153} INFO - Started process (PID=25824) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:50:29.300+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:50:29.301+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:50:29.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:50:29.316+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:50:29.315+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:50:29.317+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:50:29.329+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.044 seconds
[2022-12-15T13:51:00.048+0000] {processor.py:153} INFO - Started process (PID=25897) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:51:00.050+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:51:00.050+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:51:00.050+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:51:00.068+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:51:00.067+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:51:00.068+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:51:00.085+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.040 seconds
[2022-12-15T13:51:30.856+0000] {processor.py:153} INFO - Started process (PID=25985) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:51:30.857+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:51:30.858+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:51:30.857+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:51:30.872+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:51:30.872+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/PysparkPipelineDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PysparkPipelineDag.py", line 124, in <module>
    start_task >> select_partner_task >> load_job_params_task >> add_one >> sum_it
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 175, in _set_relatives
    task_object.update_relative(self, not upstream)
AttributeError: '_TaskDecorator' object has no attribute 'update_relative'
[2022-12-15T13:51:30.873+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:51:30.888+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.034 seconds
[2022-12-15T13:51:44.967+0000] {processor.py:153} INFO - Started process (PID=26003) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:51:44.968+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:51:44.969+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:51:44.969+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:51:44.979+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:51:45.041+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:51:45.041+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:51:45.060+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:51:45.060+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:51:45.089+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.124 seconds
[2022-12-15T13:52:00.334+0000] {processor.py:153} INFO - Started process (PID=26057) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:52:00.339+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:52:00.340+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:52:00.340+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:52:00.357+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:52:00.384+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:52:00.384+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:52:00.407+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:52:00.407+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:52:00.427+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.096 seconds
[2022-12-15T13:52:30.756+0000] {processor.py:153} INFO - Started process (PID=26139) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:52:30.768+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:52:30.768+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:52:30.768+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:52:30.780+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:52:30.819+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:52:30.818+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:52:30.848+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:52:30.847+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:52:30.865+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.112 seconds
[2022-12-15T13:53:01.025+0000] {processor.py:153} INFO - Started process (PID=26212) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:53:01.026+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:53:01.026+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:53:01.026+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:53:01.041+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:53:01.078+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:53:01.078+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:53:01.104+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:53:01.104+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:53:01.121+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.098 seconds
[2022-12-15T13:53:31.807+0000] {processor.py:153} INFO - Started process (PID=26301) to work on /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:53:31.818+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/PysparkPipelineDag.py for tasks to queue
[2022-12-15T13:53:31.819+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:53:31.819+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:53:31.829+0000] {processor.py:753} INFO - DAG(s) dict_keys(['pyspark-pipeline']) retrieved from /opt/airflow/dags/PysparkPipelineDag.py
[2022-12-15T13:53:31.860+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:53:31.859+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2022-12-15T13:53:31.880+0000] {logging_mixin.py:137} INFO - [2022-12-15T13:53:31.880+0000] {dag.py:3427} INFO - Setting next_dagrun for pyspark-pipeline to None, run_after=None
[2022-12-15T13:53:31.893+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/PysparkPipelineDag.py took 0.088 seconds
